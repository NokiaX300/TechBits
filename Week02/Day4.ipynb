{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 单节点\n",
    "# 使用 metadata 中的字段拆分 collection\n",
    "# 图索引\n",
    "# 稀疏索引\n",
    "# 3万条数据指一个 collection 中3万个 points\n",
    "# 混合检索\n",
    "# 包括向量相似度（重要）+ metadata 中的字段\n",
    "# bge\n",
    "# bm42\n",
    "# 主要看的是检索效率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosine = normalize + dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # case_0\n",
    "# # 200字\n",
    "# # case_1\n",
    "# # 2000字\n",
    "\n",
    "# # case_2\n",
    "# # 20000字\n",
    "# name = 'case_2'\n",
    "# client.create_collection(\n",
    "#     collection_name=name,\n",
    "#     vectors_config=VectorParams(size=1024, distance=Distance.COSINE),\n",
    "    \n",
    "#     # 在这里修改建库参数\n",
    "# )\n",
    "# # 不知道为啥1405个点落进去成118个了\n",
    "# # 可能是一次性上传时有上限\n",
    "# # 改为 for 循环一条一条上传\n",
    "# print(f'final_points的长度是{len(final_points)}')\n",
    "# i = 0\n",
    "# for p in final_points:\n",
    "#     client.upsert(\n",
    "#         collection_name=name,\n",
    "#         wait=False,\n",
    "#         points=[p]\n",
    "#     )\n",
    "#     i += 1\n",
    "# print(f'循环的次数是{i}')\n",
    "# count_info = client.count(collection_name='case_2', exact=True)\n",
    "# print(f'点的个数是{count_info.count}')\n",
    "# # 看一下是否成功落库 'completed'\n",
    "# # print(operation_info)\n",
    "\n",
    "# # 最终发现是录入的文本重复段落过多，导致覆盖\n",
    "# # 换源"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search\n",
    "# 主要聚焦于基于向量相似度的搜索操作\n",
    "# query_points\n",
    "# 参数类型更加多样化，可以预取，可以指定查找向量的位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_points 参数\n",
    "import Para_test.emb as emb\n",
    "from qdrant_client import QdrantClient, models\n",
    "import time\n",
    "\n",
    "def main():\n",
    "    client = QdrantClient(url=\"\")  \n",
    "\n",
    "    # 要查询的集合名称\n",
    "    collection_name = \"case_1\"  \n",
    "\n",
    "    # 查询的内容，这里是密集向量 List[float]\n",
    "    # 如果输入其他格式内容\n",
    "    # str: 字符串\n",
    "    # int: ID\n",
    "    # None: 前 limit 个点\n",
    "\n",
    "    text = '霎时间过了二百里水面'\n",
    "    vector = emb.txt_to_vec(text)\n",
    "    query = vector\n",
    "\n",
    "    # 指定要使用的向量名称，如果为 None 则使用默认向量\n",
    "    using = None\n",
    "\n",
    "    # 预取查询\n",
    "    # prefetch = models.Prefetch(\n",
    "    #     queries=[\n",
    "    #         models.Query(\n",
    "    #             vector=[0.1, 0.2, 0.3],  # 预取的查询向量\n",
    "    #             filter=models.Filter(\n",
    "    #                 must=[\n",
    "    #                     models.FieldCondition(\n",
    "    #                         key=\"category\",  # 预取过滤条件的字段\n",
    "    #                         match=models.MatchValue(value=\"books\")  # 预取过滤条件的值\n",
    "    #                     )\n",
    "    #                 ]\n",
    "    #             )\n",
    "    #         )\n",
    "    #     ]\n",
    "    # )\n",
    "\n",
    "    # 过滤\n",
    "    # 必须满足\n",
    "    # query_filter = models.Filter(\n",
    "    #                 must=[\n",
    "    #                     models.FieldCondition(\n",
    "    #                         key=\"category\",\n",
    "    #                         match=models.MatchValue(value=\"books\")\n",
    "    #                     )\n",
    "    #                 ]\n",
    "    # 满足其一\n",
    "    # should=[\n",
    "    #     models.FieldCondition(\n",
    "    #         key=\"rating\",\n",
    "    #         range=models.Range(\n",
    "    #             gte=4.0\n",
    "    #         )\n",
    "    #     )\n",
    "    # ],\n",
    "    # 必须不满足\n",
    "    # must_not=[\n",
    "    #     models.FieldCondition(\n",
    "    #         key=\"status\",\n",
    "    #         match=models.MatchValue(value=\"out_of_stock\")\n",
    "    #     )\n",
    "    # ]\n",
    "    # )\n",
    "\n",
    "    # 搜索参数\n",
    "    \"\"\"\n",
    "    调优\n",
    "    \"\"\"\n",
    "    search_params = models.SearchParams(\n",
    "        hnsw_ef=128,  # 数值越大越精确\n",
    "        exact=True,  # 是否使用精确搜索，false 会使用一些近似算法\n",
    "        quantization = None,\n",
    "        indexed_only = False\n",
    "    )\n",
    "\n",
    "    # 限制结果的数量\n",
    "    limit = 3\n",
    "\n",
    "    # 偏移量\n",
    "    offset = 0\n",
    "\n",
    "    # 是否返回 payload\n",
    "    with_payload = True  \n",
    "\n",
    "    # 是否返回 vector\n",
    "    with_vectors = False  \n",
    "\n",
    "    # 最小分数阈值\n",
    "    score_threshold = 0.5  \n",
    "\n",
    "    # 定义查找向量的位置，默认使用当前集合\n",
    "    lookup_from = None  \n",
    "\n",
    "    # 读取一致性\n",
    "    # 只有在这些被查询的副本中都存在的值才会作为结果返回\n",
    "    # 'int''majority''quorum''all'\n",
    "    consistency = 'all'\n",
    "\n",
    "    # 指定查询哪些分片\n",
    "    shard_key_selector = None  \n",
    "\n",
    "    # 超时单位为秒\n",
    "    timeout = 30  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # 执行100次查询操作\n",
    "    start_time = time.time()\n",
    "    for _ in range(100):\n",
    "        results = client.query_points(\n",
    "            collection_name=collection_name,\n",
    "            query=query,\n",
    "            using=using,\n",
    "            # prefetch=prefetch,\n",
    "            # query_filter=query_filter,\n",
    "            search_params=search_params,\n",
    "            limit=limit,\n",
    "            offset=offset,\n",
    "            with_payload=with_payload,\n",
    "            with_vectors=with_vectors,\n",
    "            score_threshold=score_threshold,\n",
    "            lookup_from=lookup_from,\n",
    "            consistency=consistency,\n",
    "            shard_key_selector=shard_key_selector,\n",
    "            timeout=timeout\n",
    "        )\n",
    "    end_time = time.time()\n",
    "    for point in results.points:\n",
    "        print(point.payload.get('page_content'))\n",
    "        print(f'分数：{point.score:.4f}')\n",
    "\n",
    "    print('\\n')\n",
    "    print(f'100次检索用时 {end_time-start_time:.4f}秒')\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ，霎时间过了二百里水面\n",
    "# 分数：0.9743\n",
    "# ，有二百里水面\n",
    "# 分数：0.8851\n",
    "# 。忽行至西洋大海\n",
    "# 分数：0.7024\n",
    "\n",
    "\n",
    "# 100次检索用时 5.0703秒"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-filtering\n",
    "# 先处理metadata\n",
    "# Post-filtering\n",
    "# 先处理近似向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建库参数\n",
    "from qdrant_client.models import Distance, models\n",
    "\n",
    "def main():\n",
    "    client = QdrantClient(url=\"\")  \n",
    "\n",
    "    # 要创建的集合名称\n",
    "    collection_name = \"case_2\"  \n",
    "\n",
    "    # 向量存储的配置\n",
    "    vectors_config = models.VectorParams(size=1024, distance=Distance.COSINE)\n",
    "\n",
    "    # 稀疏向量存储的配置\n",
    "    sparse_vectors_config = None  \n",
    "\n",
    "    # 分片数量\n",
    "    shard_number = None\n",
    "\n",
    "    # 分片方法\n",
    "    sharding_method = None\n",
    "\n",
    "    # 复制因子，在分布式模式下使用\n",
    "    replication_factor = None\n",
    "\n",
    "    # 写一致性因子，在分布式模式下使用\n",
    "    write_consistency_factor = 1  \n",
    "\n",
    "    # 是否将有效负载存储在磁盘上\n",
    "    # True 时略微增加响应时间\n",
    "    on_disk_payload = False  \n",
    "\n",
    "    # HNSW 索引配置\n",
    "    hnsw_config = models.HnswConfigDiff(\n",
    "        m=16,  # 每个节点的边数越多会增加空间时间\n",
    "        ef_construct=200  # 邻居越多时间越长\n",
    "    )\n",
    "\n",
    "    # 优化器配置\n",
    "    optimizers_config = models.OptimizersConfigDiff(\n",
    "        deleted_threshold=0.2,  # 设置删除阈值\n",
    "        vacuum_min_vector_number=1000  # 设置清理的最小向量数量\n",
    "    )\n",
    "\n",
    "    # 预写日志配置\n",
    "    wal_config = models.WalConfigDiff(\n",
    "        wal_capacity_mb=32,\n",
    "        wal_segments_ahead=0\n",
    "    )\n",
    "\n",
    "    # 量化配置\n",
    "    quantization_config = None  \n",
    "\n",
    "    # 从其他集合初始化\n",
    "    init_from = None  \n",
    "\n",
    "    # 超时时间\n",
    "    timeout = 30  \n",
    "\n",
    "    # 执行创建集合操作\n",
    "    client.create_collection(\n",
    "        collection_name=collection_name,\n",
    "        vectors_config=vectors_config,\n",
    "        sparse_vectors_config=sparse_vectors_config,\n",
    "        shard_number=shard_number,\n",
    "        sharding_method=sharding_method,\n",
    "        replication_factor=replication_factor,\n",
    "        write_consistency_factor=write_consistency_factor,\n",
    "        on_disk_payload=on_disk_payload,\n",
    "        hnsw_config=hnsw_config,\n",
    "        optimizers_config=optimizers_config,\n",
    "        wal_config=wal_config,\n",
    "        quantization_config=quantization_config,\n",
    "        init_from=init_from,\n",
    "        timeout=timeout\n",
    "    )\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提交笔记后指出切分的小块短文本映射到1024维可能会导致稀疏现象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case_8的indexed_vectors_count不为0\n",
    "# 猜测原因为indexing_threshold为800（default=20000)\n",
    "# 导致系统在数据量还相对较小的时候就开始启用向量索引(HNSW)\n",
    "\n",
    "# 注意到indexed_vectors_count=0时搜索Precision为1，如果indexed_vectors_count不为0则Precision会降低（case_8)\n",
    "# 猜测原因为一旦启用了索引，搜索操作可能会使用近似算法来提高搜索速度，从而降低精度"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
